{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Written by Dr Daniel Buscombe, Northern Arizona University\n",
    "\n",
    "> Part of a series of notebooks for image recognition and classification using deep convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an introduction to image feature extraction, which is usually a necessary step for machine learning based classifiers. This feature extraction is what deep learning tries to avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is a module for machine learning algorithms\n",
    "\n",
    "* Supervised learning\n",
    "* Unsupervised learning\n",
    "* Dimensionality reduction\n",
    "* Parameter selection\n",
    "* Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn toolbox (or sklearn) is a machine learning package built on the SciPy Stack, developed by an international community of practitioners under the leadership of a team of researchers in INRIA, France. \n",
    "\n",
    "It provides tools for regression, classification, clustering, dimensionality reduction, parameter selection and cross-validation. \n",
    "\n",
    "Gaussian mixture models, decision trees, support vector machines, and Gaussian processes are a few examples of the methods available to date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit/Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn's objects implements a fit/predict interface\n",
    "\n",
    "* fit\n",
    "    * learning step (supervised or unsupervised)\n",
    "* predict\n",
    "    * regression or classification\n",
    "* The learned model can be stored using Python’s built-in persistence model, pickle\n",
    "\n",
    "Sklearn is able to evaluate an estimator’s performance and parameters by cross-validation, optionally distributing the computation to several computer cores if necessary. The sklearn module implements machine learning algorithms as objects that provide a fit/predict interface. The fit method performs learning (supervised or unsupervised, according to the algorithm). The predict method performs regression or classification. The learned model can be saved for further usage by pickle, the Python’s built-in persistence model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in a function to read an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering/extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/traditional-ml-deep-learning-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying any ML method, you must first extract these features from your data: there is no formula for how to do this that applies across all domains, and thus this is where you as a data scientist must exercise your own intuition and expertise.\n",
    "\n",
    "Feature selection is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested.\n",
    "\n",
    "Having irrelevant features in your data can decrease the accuracy of many models, especially linear algorithms like linear and logistic regression.\n",
    "\n",
    "Three benefits of performing feature selection before modeling your data are:\n",
    "\n",
    "* Reduces Overfitting: Less redundant data means less opportunity to make decisions based on noise.\n",
    "* Improves Accuracy: Less misleading data means modeling accuracy improves.\n",
    "* Reduces Training Time: Less data means that algorithms train faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a look at just two feature extraction methods, namely HOG (histogram of oriented gradients) and PCA (principal components analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.bogotobogo.com/python/scikit-learn/images/features/FeatureExtraction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will take a look at one such feature extraction technique, the Histogram of Oriented Gradients (HOG), which transforms image pixels into a vector representation that is sensitive to broadly informative image features regardless of confounding factors like illumination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Histogram of Gradients is a straightforward feature extraction procedure that was developed in the context of identifying pedestrians within images. HOG involves the following steps:\n",
    "\n",
    "* Optionally pre-normalize images. This leads to features that resist dependence on variations in illumination.\n",
    "* Convolve the image with two filters that are sensitive to horizontal and vertical brightness gradients. These capture edge, contour, and texture information.\n",
    "* Subdivide the image into cells of a predetermined size, and compute a histogram of the gradient orientations within each cell.\n",
    "* Normalize the histograms in each cell by comparing to the block of neighboring cells. This further suppresses the effect of illumination across the image.\n",
    "* Construct a one-dimensional feature vector from the information in each cell.\n",
    "\n",
    "I think of HOG features as image 'streamlines'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries from scikit-image and call the hog function help\n",
    "from skimage import feature, color\n",
    "feature.hog?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our S3 file system utility\n",
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "root = 'esipfed/cdi-workshop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we open an image from one of the S3 datasets (specifically, an airplane)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in image\n",
    "# the open file is called 'f'\n",
    "with fs.open(root+'/imrecog_data/NWPU-RESISC45/test/airplane/airplane_700.jpg', 'rb') as f:\n",
    "    image = color.rgb2gray(imread(f, 'jpg')) #'image' is the variable that contains the contents of 'f'\n",
    "\n",
    "##extract HOG features\n",
    "_, hog_vis = feature.hog(image, visualise=True)\n",
    "# use most of the default values, but visualize = true, save visualization as 'hog_vis'\n",
    "# the underscore is used because the feature.hog() method with visualize = T returns 2 objects, the first we are not interested in so its stored as '_'\n",
    "\n",
    "##create a figure and show the input image and HOG features side by side \n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6),\n",
    "                       subplot_kw=dict(xticks=[], yticks=[]))\n",
    "# we want 2 plots together, 1 x 2 array, store their indexes as 'ax'\n",
    "ax[0].imshow(image, cmap='gray') # ax[0] means the first of two subplots\n",
    "ax[0].set_title('input image')\n",
    "\n",
    "im = ax[1].imshow(hog_vis) # ax[1] means the second of two subplots\n",
    "plt.colorbar(im)\n",
    "ax[1].set_title('visualization of HOG features');\n",
    "\n",
    "## alternatively you could create the same plot with the following code:\n",
    "\n",
    "#plt.figure(figsize=(12,6))\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.imshow(image, cmap='gray')\n",
    "#plt.title('Input Image')\n",
    "#plt.axis('off')\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.imshow(hog_vis)\n",
    "#plt.title('Visualization of HOG features')\n",
    "#plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing with algorithm inputs ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##extract HOG features\n",
    "# in this example we adjust some of the paramters from their default values, here we double the pixel size from 8x8 to 16x16\n",
    "# use 30 oreiantations instead of 9, transform_sqrt = T\n",
    "_, hog_vis = feature.hog(image, orientations=30, visualise=True, transform_sqrt=True, pixels_per_cell=(16, 16))\n",
    "\n",
    "##create a figure and show the input image and HOG features side by side \n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6),\n",
    "                       subplot_kw=dict(xticks=[], yticks=[]))\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('input image')\n",
    "\n",
    "ax[1].imshow(hog_vis)\n",
    "ax[1].set_title('visualization of HOG features');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is fundamentally a dimensionality reduction algorithm, but it can also be useful as a tool for visualization, for noise filtering, for feature extraction and engineering, and much more.\n",
    "\n",
    "PCA reduces a set of possibly correlated, high dimensional variables to a lower dimensional set of linearly correlated variables called principal components\n",
    "\n",
    "This time we're treating each pixel as a unique feature, and we'll use PCA to reduce the number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set up a dataset to use. The EuroSAT data has images in 10 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list the subdirectories of the EuroSAT data, which will be our image 'classes'\n",
    "cats = [f for f in fs.ls(root+'/imrecog_data/EuroSAT')]\n",
    "cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll import a function that will resize all images to a specified size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "files = [f for f in fs.ls(root+'/imrecog_data/UCMerced_LandUse/Images/test/freeway') if f.endswith('.jpg')]\n",
    "for file in files:\n",
    "    ##print('working on %s' % file) #uncomment this line if we want the image names printed to screen\n",
    "    with fs.open(file, 'rb') as f:\n",
    "        images.append(resize(color.rgb2gray(imread(f, 'jpg')), (128, 128)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform image data from list to numpy array\n",
    "images = np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(images) ## the shape shows 34 images which are flattened into a vector 128 * 128 (16384) values long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principal component analysis, the relationship between data dimensions is quantified by finding a list of the principal axes in the data, and using those axes to describe the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PCA for dimensionality reduction involves zeroing out one or more of the smallest principal components, resulting in a lower-dimensional projection of the data that preserves the maximal data variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of using PCA as a dimensionality reduction transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make PCA object with 1 component\n",
    "pca  =  PCA(n_components =1)\n",
    "## fit to data\n",
    "pca.fit(images)\n",
    "## apply the transformation\n",
    "images_pca = pca.transform(images)\n",
    "## compare shapes\n",
    "print(\"original shape:   \", images.shape)\n",
    "print(\"transformed shape:\", images_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformed data has been reduced to a single dimension. Then we reproject the data back using the inverse transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_new = pca.inverse_transform(images_pca)\n",
    "\n",
    "print(\"transformed shape:\", images_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the image vector and its associated reduced version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(images[0], 'k', label='Original')\n",
    "plt.plot(images_new[0], 'r', label='Transformed')\n",
    "plt.legend()\n",
    "plt.xlabel('Pixel in image')\n",
    "plt.ylabel('Pixel value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the effect of this dimensionality reduction, we can plot the inverse transform of this reduced data along with the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first feature (pixel) versus first projected feature\n",
    "plt.scatter(images[:, 0], images[:, 1], alpha=0.2)\n",
    "plt.scatter(images_new[:, 0], images_new[:, 1], color='r', alpha=0.8)\n",
    "plt.axis('equal');\n",
    "plt.xlabel('Dimension 1 (first pixel across all 34 images)')\n",
    "plt.ylabel('Dimension 2 (first pixel across all 34 projected images)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blue points are the original data, while the red points are the projected version. \n",
    "\n",
    "This makes clear what a PCA dimensionality reduction means: the information along the least important principal axis or axes is removed, leaving only the component(s) of the data with the highest variance. The fraction of variance that is cut out (proportional to the spread of points about the line formed in this figure) is roughly a measure of how much \"information\" is discarded in this reduction of dimensionality.\n",
    "\n",
    "This reduced-dimension dataset is in some senses \"good enough\" to encode the most important relationships between the points: despite reducing the dimension of the data by 50%, the overall relationship between the data points are mostly preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction of airplane images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to find 100 principal components using \n",
    "* Randomized SVD (singular value decomposition) solver\n",
    "* Whiten (vectors are multiplied by the $\\sqrt(N)$ and then divided by the singular values to ensure uncorrelated outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(svd_solver='randomized', n_components=100, whiten=True, random_state=42)\n",
    "pca.fit(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit learns some quantities from the data, most importantly the \"components\" and \"explained variance\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be interesting to visualize the images associated with the first several principal components (these components are known as \"eigenvectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 6, figsize=(15, 15),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i, ax in enumerate(axes.flat): # enumerate creats pairs of values and indexes for those values, these values are...\n",
    "    # stored as 'i' (index) and \"ax' (subplot index)\n",
    "    # axes.flat flattens the 4 x 6 grid of subplots into subplots 1 - 24, so they can be plotted sequentially\n",
    "    ax.imshow(pca.components_[i].reshape(128, 128), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vital part of using PCA in practice is the ability to estimate how many components are needed to describe the data. This can be determined by looking at the cumulative explained variance ratio as a function of the number of components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that about 20 components account for ~90% of the variance. That would lead us to believe that using these 20 components, we would recover most of the essential characteristics of the data. To make this more concrete, we can compare the input images with the images reconstructed from these 20 components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20 #new number of components\n",
    "\n",
    "pca = PCA(svd_solver='randomized', n_components=N, whiten=True, random_state=42)\n",
    "pca.fit(images)\n",
    "\n",
    "# Compute the components and projected images\n",
    "components = pca.transform(images)\n",
    "projected = pca.inverse_transform(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15, 15),\n",
    "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "for i in range(4):\n",
    "    ax[0, i].imshow(images[i].reshape(128, 128), cmap='gray')\n",
    "    ax[1, i].imshow(projected[i].reshape(128, 128), cmap='gray')\n",
    "    \n",
    "ax[0, 0].set_ylabel('full-dim\\ninput')\n",
    "ax[1, 0].set_ylabel(str(N)+'-dim\\nreconstruction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top row here shows the input images, while the bottom row shows the reconstruction of the images from just 50 of the initial features.\n",
    "\n",
    "Although it reduces the dimensionality of the data, the projected images contain enough information that we might, by eye, recognize the individuals in the image. What this means is that our classification algorithm needs to be trained on 50-dimensional data rather than very high dimensional data, which depending on the particular algorithm we choose, can lead to a much more efficient classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many principal components do you need for stationary camera time-series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have several time-series of images from a stationary camera in Grand Canyon. Such as this one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in fs.ls('cdi-workshop/semseg_data/RC1671L/flood4')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "\n",
    "with fs.open(files[0], 'rb') as f:\n",
    "    nx, ny = np.shape(imresize(color.rgb2gray(imread(f, 'jpg')), .25))\n",
    "\n",
    "images = []\n",
    "for file in files:\n",
    "    with fs.open(file, 'rb') as f:\n",
    "        images.append(imresize(color.rgb2gray(imread(f, 'jpg')), .25).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot showing all eight images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose the image into principal components. How many components are needed to explain >85% of the variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot to visualize those components. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the images into principal components, then do the inverse transform to get projected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a plot comparing the original with projected images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:conda]",
   "language": "python",
   "name": "conda-env-conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
