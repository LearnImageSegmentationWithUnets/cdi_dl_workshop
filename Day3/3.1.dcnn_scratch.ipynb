{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Deep Convolutional Neural Network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Written by Dr Daniel Buscombe, Northern Arizona University\n",
    "\n",
    "> Part of a series of notebooks for image recognition and classification using deep convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an introduction to building a convolutional neural network from scratch, for the purposes of binary image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to construct an CDNN to segment images into two classes: 'water' and 'not water'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we'll also load the [contrib.layers](https://www.tensorflow.org/api_guides/python/contrib.layers) which are high level functions for building neural network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(0)\n",
    "from tensorflow.contrib.layers import conv2d, conv2d_transpose, batch_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.stack.imgur.com/lm5wv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layers apply a specified number of convolution filters to the image. For each subregion, the layer performs a set of mathematical operations to produce a single value in the output feature map. \n",
    "\n",
    "Then a ReLU activation function is applied to the output to introduce nonlinearities into the model.\n",
    "\n",
    "Pooling layers downsample the image data extracted by the convolutional layers to reduce the dimensionality of the feature map in order to decrease processing time. Max pooling extracts subregions of the feature map, keeps their maximum value, and discards all other values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution network architecture\n",
    "\n",
    "1. Convolutional layer 1\n",
    "2. Batch normalization\n",
    "3. Pooling layer 1\n",
    "4. Residual layer 1\n",
    "5. Pooling layer 2\n",
    "6. Residual layer 2\n",
    "7. Pooling layer 3\n",
    "8. Residual layer 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolutional layer applies 32, 3x3 filters with a reLU activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.kdnuggets.com/wp-content/uploads/activation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(T, num_kernels, kernel_size, activation_fn=tf.nn.relu): \n",
    "    \"\"\"\n",
    "    2d convolution\n",
    "    \"\"\"\n",
    "    return conv2d(T, num_kernels, kernel_size, activation_fn=activation_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is batch normalization?\n",
    "* Essentially, normalizing the input layer by adjusting and scaling the activations.\n",
    "\n",
    "Why do we use batch normalization?\n",
    "\n",
    "* Batch normalization allows each layer of a network to learn by itself a little bit more independently of other layers.\n",
    "\n",
    "* We can use higher learning rates because batch normalization makes sure that there’s no activation that’s gone really high or really low. And by that, things that previously couldn’t get to train, it will start to train.\n",
    "\n",
    "* It reduces overfitting because it has a slight regularization effects. Similar to dropout, it adds some noise to each hidden layer’s activations. Therefore, if we use batch normalization, we will use less dropout, which is a good thing because we are not going to lose a lot of information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn(T):\n",
    "    \"\"\"\n",
    "    batch normalization\n",
    "    \"\"\"\n",
    "    return batch_norm(T, updates_collections=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('dXB-KQYkzNU') ## 7 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each residual layer consists of two sets of convolution followed by a batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn-images-1.medium.com/max/376/1*pUyst_ciesOz_LUg0HocYg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(T, num_kernels, kernel_size):\n",
    "    T = conv(T, num_kernels, kernel_size)\n",
    "    T = bn(T)\n",
    "    T = conv(T, num_kernels, kernel_size, activation_fn=None)\n",
    "    T = bn(T)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('ZILIbUvp5lk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pooling layer performs max. pooling with a 2x2 filter and stride of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool(T):\n",
    "    \"\"\"\n",
    "    max pooling with no overlap\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(T, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## strided convolutions\n",
    "YouTubeVideo('tQYZaDn_kSg') ## 9 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pooling layers\n",
    "YouTubeVideo('8oOgPUO-TBY') ## 10 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deconvolution network architecture\n",
    "\n",
    "1. Unpooling layer 1\n",
    "2. Transpose residual layer 1\n",
    "3. Unpooling layer 2\n",
    "4. Transpose residual layer 2\n",
    "5. Unpooling layer 3\n",
    "6. Transpose residual layer 3\n",
    "7. Transpose convolution layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An unpooling layer is a reverse convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpool(T):\n",
    "    \"\"\"\n",
    "    inverse of pooling step\n",
    "    \"\"\"\n",
    "    height, width = T.get_shape().as_list()[1:3]\n",
    "    return tf.image.resize_images(T, (height*2, width*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each transpose residual layer consists of two sets of transpose convolution and batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residualT(T, num_kernels, kernel_size):\n",
    "    T = convT(T, num_kernels, kernel_size)\n",
    "    T = bn(T)\n",
    "    T = convT(T, num_kernels, kernel_size, activation_fn=None)\n",
    "    T = bn(T)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convT(T, num_kernels, kernel_size, activation_fn=tf.nn.relu):\n",
    "    \"\"\"\n",
    "    transpose of 2d convolution\n",
    "    \"\"\"\n",
    "    return conv2d_transpose(T, num_kernels, kernel_size, activation_fn=activation_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcd(a,b):\n",
    "    \"\"\"Compute the greatest common divisor of a and b\"\"\"\n",
    "    while b > 0:\n",
    "        a, b = b, a % b\n",
    "    return a\n",
    "\n",
    "def flatten(T):\n",
    "    flat_size = np.prod(T.get_shape().as_list()[1:])\n",
    "    return tf.reshape(T, [-1, flat_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other functions for getting batches of images and masks, patches of pixels within images, and creating test and train data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## given an array of images and associated masks, choose one at random\n",
    "def get_random_image_and_mask(images_and_masks):\n",
    "    return random.choice(images_and_masks)\n",
    "\n",
    "## get a randomly selected patch of pixels from an image, with given dimensions\n",
    "def get_random_patch(images_and_masks, patch_height, patch_width):\n",
    "    image, mask = get_random_image_and_mask(images_and_masks)\n",
    "    \n",
    "    image_height, image_width, image_channels = image.shape\n",
    "    assert(image_channels == 3)\n",
    "    \n",
    "    x = np.random.randint(image_width - patch_width)\n",
    "    y = np.random.randint(image_height - patch_height)\n",
    "    \n",
    "    image_patch = image[y:y+patch_height, x:x+patch_width]\n",
    "    mask_patch  = mask [y:y+patch_height, x:x+patch_width]\n",
    "    \n",
    "    return image_patch, mask_patch\n",
    "\n",
    "## select a random batch of images and masks\n",
    "def get_random_batch(images_and_masks, batch_size, patch_height, patch_width):\n",
    "    image_patches = []\n",
    "    mask_patches = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        image_patch, mask_patch = get_random_patch(images_and_masks, patch_height, patch_width)\n",
    "        \n",
    "        image_patches.append(image_patch)\n",
    "        mask_patches.append(mask_patch)\n",
    "\n",
    "    return image_patches, mask_patches\n",
    "\n",
    "## create training and testing sets given user-specified split\n",
    "def split_train_test(values, test_ratio = 0.2):\n",
    "    # split [values] into [train values] + [test values]\n",
    "    \n",
    "    n = len(values)\n",
    "    n_train = n - int(n*test_ratio)\n",
    "\n",
    "    train = values[:n_train]\n",
    "    test  = values[n_train:]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing a test and train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [f for f in fs.ls('cdi-workshop/semseg_data/ontario/train') if f.endswith('.JPG')]\n",
    "image_files.extend([f for f in fs.ls('cdi-workshop/semseg_data/ontario/test') if f.endswith('.JPG')])\n",
    "imsize = 0.125\n",
    "len(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import imresize\n",
    "from imageio import imread\n",
    "\n",
    "images = []\n",
    "for file in image_files:\n",
    "    with fs.open(file, 'rb') as f:\n",
    "        images.append(imresize(imread(f), imsize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_files = [f for f in fs.ls('cdi-workshop/semseg_data/ontario/train') if f.endswith('.mat')]\n",
    "class_files.extend([f for f in fs.ls('cdi-workshop/semseg_data/ontario/test') if f.endswith('.mat')])\n",
    "len(class_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are stored in .mat format. Water is class '2'\n",
    "\n",
    "We load in each file, binarize it (water=0, not water=1), and resize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "classes = []\n",
    "for file in class_files:\n",
    "    print(\"Working on %s\" % file.split(os.sep)[-1])\n",
    "    with fs.open(file, 'rb') as f:\n",
    "        tmp = (loadmat(f)['class']!=2).astype('uint8')\n",
    "        classes.append(imresize(tmp, imsize).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(121); plt.imshow(images[0])\n",
    "plt.subplot(122); plt.imshow(classes[0], cmap=plt.cm.binary_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of all images and masks together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_and_masks = []\n",
    "for image, mask in zip(images, classes):\n",
    "    images_and_masks.append((image.astype(np.float32)/255.0, mask.astype(np.float32)/255.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images_and_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(patch_width, batch_size, kernel_size, num_kernels, n, n_batches, imsize, train_im_n_masks, test_im_n_masks):\n",
    "\n",
    "   patch_height = patch_width\n",
    "\n",
    "   image_patch_init = tf.placeholder(tf.float32, [None, patch_width, patch_height, 3])\n",
    "   mask_patch_init  = tf.placeholder(tf.float32, [None, patch_width, patch_height, 1])\n",
    "\n",
    "   # set up residual convolutional network architecture \n",
    "   T = image_patch_init\n",
    "   T = conv(T, num_kernels, kernel_size) ##16\n",
    "   T = bn(T)\n",
    "    \n",
    "   ##cycle through n pooling-residual steps\n",
    "   for _ in range(n):\n",
    "      T = pool(T)\n",
    "      T += residual(T, num_kernels, kernel_size) ##16\n",
    "\n",
    "   ##cycle through n unpooling-residual steps\n",
    "   for _ in range(n):\n",
    "      T = unpool(T)\n",
    "      T += residualT(T, num_kernels, kernel_size) ##16\n",
    "    \n",
    "   T = convT(T, 1, kernel_size, activation_fn=None)\n",
    "\n",
    "   pred_mask_patches = T\n",
    "\n",
    "   ##l2 loss\n",
    "   diff = tf.abs(pred_mask_patches - mask_patch_init)\n",
    "   loss_fn = tf.reduce_mean(diff**2)\n",
    "\n",
    "   # adam optimizer requires the least amount of work to train\n",
    "   optimizer = tf.train.AdamOptimizer()\n",
    "   trainer = optimizer.minimize(loss_fn)\n",
    "\n",
    "   # make a tensorflow session\n",
    "   sess = tf.InteractiveSession()\n",
    "\n",
    "   # initialize weights and stuff\n",
    "   initializer = tf.global_variables_initializer()\n",
    "   sess.run(initializer)\n",
    "\n",
    "   # train the model\n",
    "   last_print_time = 0\n",
    "   for batch in range(n_batches + 1):\n",
    "      # make a batch of patches\n",
    "      image_patches, mask_patches = get_random_batch(train_im_n_masks, batch_size, patch_height, patch_width)\n",
    "\n",
    "      #deal with the possibility of empty patches\n",
    "      ind = []\n",
    "      for k in range(len(mask_patches)):\n",
    "         if mask_patches[k].size==0: \n",
    "            ind.append(k)\n",
    " \n",
    "      for x in ind[::-1]:\n",
    "         del mask_patches[x]\n",
    "         del image_patches[x]\n",
    "\n",
    "      try:\n",
    "         # feed it to the neural net\n",
    "         feed_dict = {\n",
    "           image_patch_init: image_patches,\n",
    "           mask_patch_init: mask_patches,\n",
    "         }\n",
    "         _, train_loss = sess.run([trainer, loss_fn], feed_dict=feed_dict)\n",
    "\n",
    "         # print training error every second\n",
    "         time_since_last_print = time.clock() - last_print_time\n",
    "         if time_since_last_print > 1.0:\n",
    "            print(\"batch number =%5d, training loss =%f\"%(batch, train_loss))\n",
    "            last_print_time = time.clock()\n",
    "\n",
    "         # check test error every 50 iterations\n",
    "         if batch % 50 != 0: continue\n",
    "\n",
    "         # check test loss\n",
    "         image_patches, mask_patches = get_random_batch(test_im_n_masks, batch_size, patch_height, patch_width)\n",
    "\n",
    "         #deal with the possibility of empty patches\n",
    "         ind = []\n",
    "         for k in range(len(mask_patches)):\n",
    "            if mask_patches[k].size==0: \n",
    "               ind.append(k)\n",
    "\n",
    "         for x in ind[::-1]:\n",
    "            del mask_patches[x]\n",
    "            del image_patches[x]\n",
    "\n",
    "         feed_dict = {\n",
    "           image_patch_init: image_patches,\n",
    "           mask_patch_init: mask_patches,\n",
    "         }\n",
    "    \n",
    "         test_loss = sess.run(loss_fn, feed_dict=feed_dict)\n",
    "\n",
    "         print(\"#\"*40)\n",
    "         print(\"testing loss =%f\"%test_loss)\n",
    "         print(\"#\"*40)\n",
    "\n",
    "      except:\n",
    "         pass\n",
    "\n",
    "   # save the model\n",
    "   saver = tf.train.Saver()\n",
    "\n",
    "   tf.add_to_collection('loss', loss_fn)\n",
    "   tf.add_to_collection('train', trainer)\n",
    "   tf.add_to_collection('pred_mask_patches', pred_mask_patches)\n",
    "   tf.add_to_collection('image_patch_init', image_patch_init)\n",
    "   tf.add_to_collection('mask_patch_init', mask_patch_init)\n",
    "\n",
    "   try:\n",
    "      os.mkdir(\"model_\"+str(imsize)+\"_\"+str(patch_width))\n",
    "   except:\n",
    "      pass\n",
    "\n",
    "   saver.save(sess, \"model_\"+str(imsize)+\"_\"+str(patch_width)+os.sep+\"model\")\n",
    "   sess.close()\n",
    "   tf.reset_default_graph()\n",
    "   del sess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "we'll train with different patch widths and associated batch sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches  = 600 #400 \n",
    "# size of kernel in convolution\n",
    "kernel_size = 3 \n",
    "# number of kernels of size kernel_size x kernel_size\n",
    "num_kernels = 16 \n",
    "#number of pooling layers\n",
    "n = 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_im_n_masks, test_im_n_masks = split_train_test(images_and_masks, test_ratio=.2)\n",
    "#del images_and_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_im_n_masks))\n",
    "print(len(test_im_n_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the structure of this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(121); plt.imshow(test_im_n_masks[0][0])\n",
    "plt.subplot(122); plt.imshow(test_im_n_masks[0][1], cmap=plt.cm.binary_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train using different patch widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patch_width in [16, 32, 64, 128, 256]:\n",
    "\n",
    "   print(\"Procesing: %i\" % patch_width)\n",
    "   if patch_width == 16:\n",
    "      batch_size = 2000 #1000\n",
    "   elif patch_width == 32:\n",
    "      batch_size = 1000 #500\n",
    "   elif patch_width == 64:\n",
    "      batch_size = 500 #250   \n",
    "   elif patch_width == 128:\n",
    "      batch_size = 250 ##125\n",
    "   elif patch_width == 256:\n",
    "      batch_size = 125 ##125\n",
    "        \n",
    "   train(patch_width, batch_size, kernel_size, num_kernels, n, n_batches, imsize, train_im_n_masks, test_im_n_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create a function that uses the model to make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pred(impad, height, width, kernel_size, num_patches, path):\n",
    "\n",
    "   # load the model \n",
    "   sess = tf.Session() #InteractiveSession()\n",
    "   new_saver = tf.train.import_meta_graph(\"./%s/model.meta\"%path)\n",
    "   new_saver.restore(sess, tf.train.latest_checkpoint('./%s/'%path))\n",
    "\n",
    "   pred_mask_patches = tf.get_collection('pred_mask_patches')[0]\n",
    "   image_patch_init = tf.get_collection('image_patch_init')[0]\n",
    "   mask_patch_init = tf.get_collection('mask_patch_init')[0]\n",
    "\n",
    "   patch_height = patch_width = kernel_size\n",
    "\n",
    "   # Only the prediction at the center of a patch is correct\n",
    "   # so we make a weight patch to weight the predicted mask patch appropriately.\n",
    "   x = np.linspace(-1, +1, patch_width)\n",
    "   y = np.linspace(-1, +1, patch_height)\n",
    "   X, Y = np.meshgrid(x, y)\n",
    "   dist = smoothstep(1.3, 0.3, np.sqrt(X*X + Y*Y))\n",
    "   weight_patch = dist.reshape((patch_height, patch_width, 1))\n",
    "\n",
    "   # take random patches from within the orig image bounds\n",
    "   image_patches = []\n",
    "   patch_pos = []\n",
    "   for i in range(num_patches):\n",
    "      x = np.random.randint(width  + patch_width) + width  - patch_width\n",
    "      y = np.random.randint(height + patch_height) + height - patch_height\n",
    "    \n",
    "      image_patch = impad[y:y+patch_height, x:x+patch_width]\n",
    "    \n",
    "      image_patches.append(image_patch)\n",
    "      patch_pos.append((y, x))\n",
    "\n",
    "   # predict the object mask for those patches\n",
    "   feed_dict = {image_patch_init: image_patches}\n",
    "   mask_patches = sess.run(pred_mask_patches, feed_dict=feed_dict)\n",
    "\n",
    "   sess.close()\n",
    "\n",
    "   # stitch the object masks back together while weighting them\n",
    "   pred_mask = np.zeros(impad.shape)\n",
    "   weight = np.zeros(impad.shape)\n",
    "\n",
    "   w = np.median(weight_patch)\n",
    "   for mask_patch, p in zip(mask_patches, patch_pos):\n",
    "      y, x = p\n",
    "\n",
    "      mask_patch[mask_patch<0] = np.nan\n",
    "      pred_mask[y:y+patch_height*2, x:x+patch_width*2, :] += np.nanmedian(mask_patch)*w\n",
    "      weight[y:y+patch_height*2, x:x+patch_width*2, :] += w\n",
    "\n",
    "   # only need first layers\n",
    "   pred_mask = np.mean(pred_mask, axis=2)\n",
    "   weight = np.mean(weight, axis=2)\n",
    "\n",
    "   # normalize the masks by weight\n",
    "   pred_mask /= weight + 0.001\n",
    "\n",
    "   # extract just the center image \n",
    "   pred_mask = pred_mask[1*height:2*height, 1*width:2*width] #, :]\n",
    "\n",
    "   tf.reset_default_graph()\n",
    "   del sess\n",
    "   return pred_mask/np.max(pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##======================================================\n",
    "def smoothstep(edge0, edge1, x):\n",
    "    # https://www.opengl.org/sdk/docs/man/html/smoothstep.xhtml\n",
    "    t = np.clip((x - edge0)/(edge1 - edge0), 0.0, 1.0)\n",
    "    return t*t*(3.0 - 2.0*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = 32\n",
    "num_patches = 1000\n",
    "\n",
    "patch_height = kernel_size\n",
    "\n",
    "path = 'model_'+str(imsize)+'_'+str(kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimage = train_im_n_masks[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more function! This one pads an image using mirroring, to minimize edge effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded_image(testimage):\n",
    "    height, width, n_channels = testimage.shape\n",
    "    impad = np.zeros((height*3, width*3, n_channels))\n",
    "\n",
    "    impad[1*height:2*height, 1*width:2*width, :] = testimage\n",
    "    impad[0*height:1*height, 1*width:2*width, :] = np.flipud(testimage)\n",
    "    impad[2*height:3*height, 1*width:2*width, :] = np.flipud(testimage)\n",
    "    impad[1*height:2*height, 0*width:1*width, :] = np.fliplr(testimage)\n",
    "    impad[1*height:2*height, 2*width:3*width, :] = np.fliplr(testimage)\n",
    "\n",
    "    impad[0*height:1*height, 0*width:1*width, :] = np.flipud(np.fliplr(testimage))\n",
    "    impad[2*height:3*height, 0*width:1*width, :] = np.flipud(np.fliplr(testimage))\n",
    "    impad[0*height:1*height, 2*width:3*width, :] = np.flipud(np.fliplr(testimage))\n",
    "    impad[2*height:3*height, 2*width:3*width, :] = np.flipud(np.fliplr(testimage))\n",
    "    \n",
    "    return height, width, impad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width, impad = get_padded_image(testimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = make_pred(impad, height, width, kernel_size, num_patches, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot to see the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(testimage)\n",
    "plt.imshow(P, alpha=0.5, cmap=plt.cm.bwr)\n",
    "cb = plt.colorbar(shrink=0.5)\n",
    "cb.set_label('Probability of land')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    testimage = test_im_n_masks[i][0]\n",
    "    height, width, impad = get_padded_image(testimage)\n",
    "    P = make_pred(impad, height, width, kernel_size, num_patches, path)\n",
    "    axi.imshow(testimage)\n",
    "    axi.imshow(P, alpha=0.5, cmap=plt.cm.bwr)\n",
    "    axi.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-scalar prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we trained at multiple scales, we can also test at those scales and merged predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##testimage = test_im_n_masks[1][0]\n",
    "testimage = train_im_n_masks[0][0]\n",
    "\n",
    "height, width, impad = get_padded_image(testimage)\n",
    "\n",
    "kernel_size = [32, 64, 128, 256]\n",
    "\n",
    "num_patches = [2000, 1000, 500, 250]\n",
    "\n",
    "patch_height = np.min(kernel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model for all kernel sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = []\n",
    "for n in range(len(kernel_size)):\n",
    "    path = 'model_'+str(imsize)+'_'+str(kernel_size[n])\n",
    "    P.append(make_pred(impad, height, width, kernel_size[n], num_patches[n], path))\n",
    "\n",
    "for n in range(len(kernel_size)):\n",
    "    P[n][P[n]==0] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(testimage)\n",
    "    axi.imshow(P[i], alpha=0.5, cmap=plt.cm.bwr)\n",
    "    axi.axis('off')\n",
    "    axi.set(title='Kernel size: '+str(kernel_size[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a median per pixel through the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.nanmean(np.dstack(P), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "def rescale(dat,mn,mx):\n",
    "    '''\n",
    "    rescales an input dat between mn and mx\n",
    "    '''\n",
    "    m = min(dat.flatten())\n",
    "    M = max(dat.flatten())\n",
    "    return (mx-mn)*(dat-m)/(M-m)+mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rescale(pred, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(testimage)\n",
    "plt.imshow(pred, alpha=0.5, cmap=plt.cm.bwr)\n",
    "cb = plt.colorbar(shrink=0.5)\n",
    "cb.set_label('Probability of Land')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way would be to define a global threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(testimage)\n",
    "plt.imshow(pred>.5, alpha=0.5, cmap=plt.cm.bwr)\n",
    "cb.set_label('Land')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't optimal, and probably wouldn't generalize well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to use a generative ML algorithm to model the likelihood of the 2 classes\n",
    "\n",
    "Let's use a Gaussian Mixture model, which is something we have used before. The following function will read the image and associated land probability, and fit a N component GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "\n",
    "##======================================================\n",
    "def GMM(im1, im, numclusters, maxiter):\n",
    "   \"\"\"\n",
    "   takes an RGB image and a probability layer and computes\n",
    "   an N-component (4-dimensional) Gaussian mixture model\n",
    "   then recasts predictions in a 2D, N-component label map\n",
    "   \"\"\"\n",
    "   \n",
    "   X = np.c_[im1.flatten(), im[:,:,0].flatten(), im[:,:,1].flatten(), im[:,:,2].flatten()] \n",
    "\n",
    "   # Fit a Gaussian mixture\n",
    "   dpgmm = mixture.GaussianMixture(n_components=numclusters, covariance_type='full', max_iter=maxiter).fit(X) \n",
    "   Yb = dpgmm.predict(X)\n",
    "   return  Yb.reshape(im.shape[0], im.shape[1])##, probs.reshape(im.shape[0], im.shape[1],numclusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, below we fit a 5-component GMM, similar to what we did on Day 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numclusters = 5 #number of clusters for GMM\n",
    "maxiter = 50 #maximum iterations in GMM\n",
    "\n",
    "p = GMM(pred, testimage, numclusters, maxiter)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function below will compute the median probability associated with each component, then mask the probabilities less than a specified threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##======================================================\n",
    "def GMM_mask_multi(pred_mask, image, maxiter, patch_height, prob_thres, numclusters):\n",
    "   \"\"\"\n",
    "   implements GMM with nan replacement and checks on outputs\n",
    "   \"\"\"\n",
    "\n",
    "   pred_mask[np.isinf(pred_mask)] = np.nanmean(pred_mask)\n",
    "   pred_mask[np.isnan(pred_mask)] = np.nanmean(pred_mask)\n",
    "\n",
    "   p = GMM(pred_mask, image, numclusters, maxiter)\n",
    "\n",
    "   c = [np.nanmedian(pred_mask[p==k]) for k in range(numclusters)]\n",
    "\n",
    "   if (np.all(np.asarray(c)>prob_thres) or np.all(np.asarray(c)<prob_thres)):\n",
    "      prob_thres = np.mean(c)\n",
    "      print(\"Revising probability threshold to %f\"%prob_thres)\n",
    "\n",
    "   mask = np.zeros(np.shape(p))\n",
    "   for val in np.where(np.asarray(c)>prob_thres)[0]:\n",
    "      mask[p==val] = 1\n",
    "\n",
    "   return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_thres = 0.5 #greater than this is kept in multi-part GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = GMM_mask_multi(pred, testimage, maxiter, patch_height, prob_thres, numclusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(testimage)\n",
    "plt.imshow(p, alpha=0.5, cmap=plt.cm.bwr)\n",
    "cb.set_label('Land')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
