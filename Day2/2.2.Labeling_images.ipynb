{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Label Images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Written by Dr Daniel Buscombe, Northern Arizona University\n",
    "\n",
    "> Part of a series of notebooks for image recognition and classification using deep convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Pixel-Scale Label Images (a.k.a \"Ground truth\")\n",
    "\n",
    "* All/any ML or DL image classification requires you to have a set of labeled images for training, AND a set of labeled images for testing\n",
    "* Often, creating such ground truth data can be time-consuming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to create a ground truth (label) image using a weakly supervised conditional random field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is something we can't do in the notebook because it involves interacting with graphics. So, you'll be running this on your laptop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/dl_tools_label.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label_1image_crf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script is part of the ```dl_tools``` package. \n",
    "\n",
    "You will run this script on your own PC, from an anaconda prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python create_groundtruth\\label_1image_crf.py -w 500 -s 0.125```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* -w : window size in pixels. The program is designed to work on portions of the image. This flag sets the size of the chunk of each image you will work with\n",
    "\n",
    "* -s : downscaling factor. Use this flag to resize the image (for the CRF part of the algorithm, to save time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. conda activate dl_tools (or whatever you called your conda environment)\n",
    "2. navigate to dl_tools \n",
    "3. cd create_groundtruth\n",
    "3. ```python label_1image_crf.py -w 500 -s 0.125```\n",
    "4. You will first be prompted to select an image to work on\n",
    "5. Next, you will be promted to select a labels file\n",
    "6. Finally, you will be prompted to select a colors file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each chunk, cycling through a pre-defined set of classes, you will be prompted to draw (using the cursor) example regions of the image that correspond to each label. \n",
    "\n",
    "These annotations should be exemplative, i.e., a relatively small portion of the region in the chunk that pertains to the class, rather than delimiting the entire region within the chunk that pertains to the class. \n",
    "\n",
    "Typically, the CRF algorithm only requires a few example annotations for each class. \n",
    "\n",
    "For very heterogeneous scenes, however, where each class occurs in several regions across the image, example annotations should be provided for each class in each region where that class occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll select an image from the [Google Drive](https://drive.google.com/open?id=1IhStVBhWMKLZUWIprti6zZyOg32-W4Of)\n",
    "\n",
    "* The images are located in semseg_data/Monterey_scarps/test. We'll use [this one](https://drive.google.com/open?id=1ZVYXp4h6dtduhCyliNVFrgbW9jkSENer)\n",
    "\n",
    "* The labels are located in semseg_data/Monterey_scarps/labels. We'll use [this one](https://drive.google.com/open?id=1XYkpKZmu1jZsQX72b_FlxKyvMyOxqn5O)\n",
    "\n",
    "* The label colors are located in semseg_data/Monterey_scarps/labels. We'll use [this one](https://drive.google.com/open?id=1pKCLUSdeW1EDQMYUcpEOdheDAdYlRogl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download each of these three files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/downloads.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should notice that there is one color in label_colors.txt per class in labels.txt. The colors can be matplotlib color strings (for example, r, g, b, m, k, y, c) or html color codes\n",
    "\n",
    "* Open anaconda prompt, navigate (```cd```) to ```dl_tools``` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Activate ```dl_tools``` conda environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax I will use is below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python create_groundtruth/label_1image_crf.py -w 500 -s 0.2```\n",
    "\n",
    "which says I will be using a 500x500 pixel window of the image at any one time, and the image will be rescaled to 20% of its original size to do the CRF processing (for speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/label_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, it prompts you to select an image you wish to create a label image for\n",
    "\n",
    "(currently, JPG, jpg, jpeg, png, PNG, tif, tiff, TIF and TIFF extensions supported)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/pick_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, it prompts you to select a labels file (a text file containing classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/pick_labels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same for the label colors file (text file containing a color per row in labels file)\n",
    "\n",
    "Then it displays the whole image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a portion of the image (a 500 x 500 pixel window because our ```w``` parameter was 500). Notice that the title of the small window indicates which class it expects example annotations for (in the case below, \"agricultural\" land)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/tile.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the smaller window that you annotate with the cursor. The larger image is just to show you where you are in the image. You'll notice the command window gives you further instruction for how to change the size of the brush. It also tells you that when you are finished with a class/window, hit the ```Esc``` key to progress to the next class/window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/cmd_label.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotate each class present in each tile. This should be exemplative, not exhaustive.\n",
    "\n",
    "Active annotations are red. Previous annotations (from other classes) are black.\n",
    "\n",
    "Hitting the 'Z' key on your keyboard will remove your last annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/active_anno.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished annotating, the windows will disappear and the terminal will look like this\n",
    "\n",
    "The program is using an algorithm to estimate the class of each pixel, based on the spare annotations you provided\n",
    "\n",
    "CRF inference time depends primarily on image complexity and size, but is also secondarily affected by the number and spatial heterogeneity of the class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/generating.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a couple of minutes, the labeling is complete. In the same folder as the image (and labels), you should see 3 new files\n",
    "\n",
    "![](figs/outputs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a file ending in \"mres.png\" that shows the input image, your annotations, and the final estimated label image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/D800_20160308_221757-0_mres.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A \".mat\" file containing the results. Note, this is NOT a Microsoft access database. It is matlab format. However, you won't need matlab to read this file. I will show you how to read this file in python later\n",
    "\n",
    "* The last file is a \".txt\" file that contains a report detailing the relative proportions of each class in the image, and how long it took you to annotate the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "* This process works best with smallish images (typically less than 10000 x 10000 pixels), so you may have to crop/tile larger imagery\n",
    "* Try to annotate a few examples of each class in each part of the image where they occur. Don't annotate in just one region of the image. This is because the CRF algorithm uses spatial information in its predictions\n",
    "* There are no rules as to how much annotation is required. It depends on the image. Try a few different levels of annotation, from really sparse to really dense, and evaluate how much annotation is necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A .mat file is created that contains the results. It is a binary format (the same as matlab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "dat = loadmat('D800_20160308_221757-0_mres.mat')\n",
    "dat.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are these variables?\n",
    "\n",
    "1. ```sparse```\n",
    "    * the DCNN-derived unary potentials\n",
    "2. ```class```\n",
    "    * the pixelwise label\n",
    "3. ```labels```\n",
    "    * the class names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "im2 = ax1.imshow(dat['sparse'], cmap='bwr')\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\")\n",
    "cb=plt.colorbar(im2, cax=cax)\n",
    "cb.ax.tick_params(labelsize=6)\n",
    "\n",
    "ax1 = fig.add_subplot(122)\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "im2 = ax1.imshow(dat['class'], cmap='bwr')\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\")\n",
    "cb=plt.colorbar(im2, cax=cax)\n",
    "cb.ax.tick_params(labelsize=6)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image pixels and associated labels are mapped to a computational graph\n",
    "\n",
    "![](figs/Picture11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The joint probability of the image features given the labels is modelled as the product of two functions (called potentials) that are minimized using optimization techniques\n",
    "\n",
    "![](figs/Picture12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our annotations are one potential - the computational cost of assigning a given label to a given node\n",
    "\n",
    "![](figs/Picture13.png)\n",
    "\n",
    "The other (pairwise) potentials are the cost of simultaneously assigning label yi to node i and label yj to node j\n",
    "\n",
    "![](figs/Picture14.png)\n",
    "\n",
    "And this is all solved simultaneously using an iterative algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Have a go yourself, on a dataset of your own choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention GeoTIFF users!\n",
    "\n",
    "There is a special version of this annotation program for geoTIFF format\n",
    "\n",
    "There are other python libraries you'll need to use it:\n",
    "\n",
    "```conda install rasterio gdal```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program is called like this:\n",
    "    \n",
    "```python create_groundtruth\\label_1geotiff_crf.py -w 500 -s 1.0``` \n",
    "\n",
    "and works the same as the program for photographic imagery. The resulting label image is in the same projection as the input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example image and resulting label is provided:\n",
    "\n",
    "![](figs/elwha.png)\n",
    "![](figs/elwha_class.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
